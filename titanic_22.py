# -*- coding: utf-8 -*-
"""titanic 2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19BbAVAnj2MvgUKrJdeV9c0LAIrA_SuGK
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from google.colab import files
uploaded = files.upload()

uploaded = files.upload()

df=pd.read_csv('train.csv')
test=pd.read_csv('test.csv')
#change name col
combine = [df,test]
for dataset in combine:
    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\.', expand=False)

#pd.crosstab(n['Title'], n['Sex'])
for dataset in combine:
    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col', 	'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')

    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')
    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')
    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')
    
df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()
title_mapping = {"Mr": 1, "Miss": 2, "Mrs": 3, "Master": 4, "Rare": 5}
for dataset in combine:
    dataset['Title'] = dataset['Title'].map(title_mapping)
    dataset['Title'] = dataset['Title'].fillna(0)

df.head()
df = df.drop(['Name'], axis=1)
test =test.drop(['Name'], axis=1)

#fill age col and remove col 
c=[df,test]
for dataset in c:
   mean=dataset.Age.mean()
   dataset.Age=dataset.Age.fillna(mean)
   #dataset=dataset.drop(['PassengerId','Ticket','Cabin',],axis=1)
   #dataset=pd.get_dummies(dataset,drop_first=True)
df=df.drop(['PassengerId','Ticket','Cabin','Pclass'],axis=1)
test=test.drop(['PassengerId','Ticket','Cabin','Pclass'],axis=1)

#age bands
c=[df,test]
for dataset in c:   
    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0
    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1
    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2
    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3
    dataset.loc[ dataset['Age'] > 64, 'Age']=4

#fare bands
test['Fare'].fillna(test['Fare'].dropna().median(), inplace=True)
c=[df,test]
for dataset in c:   
    dataset.loc[ dataset['Fare'] <= 10.0, 'Fare'] = 0
    dataset.loc[(dataset['Fare'] > 10.0) & (dataset['Fare'] <= 20.0), 'Fare'] = 1
    dataset.loc[(dataset['Fare'] > 20.0) & (dataset['Fare'] <= 30.0), 'Fare'] = 2
    dataset.loc[(dataset['Fare'] > 30.0) & (dataset['Fare'] <= 40.0), 'Fare'] = 3
    dataset.loc[ dataset['Fare'] > 40.0, 'Fare']=4

df['Embarked'] = df['Embarked'].fillna('S')
c=[df,test]
for dataset in c:
    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)
df=pd.get_dummies(df ,drop_first=True)
test=pd.get_dummies(test,drop_first=True)
x=df.drop(['Survived'],axis=1)
y=df.Survived

df

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(x, y,test_size = 0.2, random_state=9)
from sklearn.preprocessing import StandardScaler
sc_x=StandardScaler()
X_train=sc_x.fit_transform(X_train)
X_test=sc_x.transform(X_test)
test=sc_x.transform(test)



from sklearn import svm
model = svm.SVC(kernel='rbf',C=0.3,gamma=0.14) 
model.fit(X_train, y_train)
predicted= model.predict(X_test)
model.score(X_test, y_test)

from sklearn.model_selection import GridSearchCV
para=[{'C':[1,0.1,0.3,0.5,1.2],'kernel':['linear']},
     {'C':[1,0.1,0.3,2,1.2],'kernel':['rbf'],'gamma':[0.05,0.1,0.08,0.3,0.14]}]
gds=GridSearchCV(estimator=model,
                param_grid=para,
                scoring='accuracy',
                cv=10)
gdss=gds.fit(X_train,y_train)
gdss.best_params_

#confusion matrix
from sklearn.metrics import confusion_matrix
cm=confusion_matrix(y_test,predicted)
cm

#cross validation
from sklearn.model_selection import cross_val_score
cv_results = cross_val_score(model,X_train, y_train, cv=5)
print(cv_results)

from xgboost import XGBClassifier
cl=XGBClassifier(learning_rate=0.05)
cl.fit(X_train,y_train)
predicted=cl.predict(X_test)
cl.score(X_train,y_train)

cm=confusion_matrix(y_test,predicted)
cm

a=cl.predict(test)
#for i in range(418):
# print(a[i])

from sklearn.ensemble import RandomForestClassifier as rfc
m=rfc(n_estimators=10)
m.fit(X_train,y_train)
m.score(X_train,y_train)

a=m.predict(test)
for i in range(418):
 print(a[i])

